\chapter{Prefix Sums}

Since there was a prefix sum project in each assignment section we decided to do them all to get a good feeling how the used frameworks can cope with it and how differently one has to implement the same algorithms in them.

For data preparation and checking the result we shared the same code between the projects which is of course comfortable, but such unification can also hide problems.

One example we discovered was that (depending on the actual values in the array) the prefix sums easily overflow the data types normally used, without getting caught by our checking algorithm - in all projects.
The checking algorithm uses the same data type\footnote{Namely \texttt{ATYPE} specifiable in all makefiles.} as the tested ones and hence overflows in the same manner.

Checking for overflows in prefix sums is of course easy because they are monotonically increasing, but we refrained from that because the overflows do not change the timing and the correct values are as good as the wrong ones as long as the algorithm is correct in general.
We did also use a single input generating function namely a counter to feed the algorithms with the same rationale: performance does not rely on the actual input.
This has just been assumed though and we would like to hear from you if you disagree.

All algorithms use \texttt{uint} as the type for counters and the user needs to take care of defining it sufficiently large in \texttt{util.h}.
The default is \texttt{unsigned int} which should be good for the expected use cases with arrays smaller then $2^{32}$ elements.
Most toolchains on modern computers use 64bit integers anyway and we did not do exhausting tests or analysis to find the exact limits.

The makefiles allow to leave out all \texttt{printfs} via their \texttt{fast} target which was used for benchmarking.
The default compile target is \texttt{debug} which enables all \texttt{printfs} and debug symbols.

\section{OpenMP Prefix Sums}

The first project was to implement three ``major'' parallel prefix sum algorithms: the one using an auxiliary array, one that does not need this and the more sophisticated one presented by Hillis et al.
The assignment required to implement \textbf{non-invasive} ``performance counters'' in a quite complicated way, but we decided to use reduction clauses only because they are very convenient to work with and if measuring the operations needs to be done in a less invasive manner we would suggest to compile the probing interface out with preprocessor directives instead of trying to make it as fast as possible.

The OpenMP proved to be very easy to work with: the pragmas are easy to learn and use and the tool chain support was sufficient and uncomplicated.


\pgfplotstableread[format=file,col sep=comma]{../../../data/1-openmp/p1/seq-n.processed}\openmpprefixseqn
\pgfplotstableread[format=file,col sep=comma]{../../../data/1-openmp/p1/auxarr-n.processed}\openmpprefixauxarrn
\pgfplotstableread[format=file,col sep=comma]{../../../data/1-openmp/p1/inplace-n.processed}\openmpprefixinplacen
\pgfplotstableread[format=file,col sep=comma]{../../../data/1-openmp/p1/hillis-n.processed}\openmpprefixhillisn

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	]

	%\addplot [stack plots=y, fill=none, draw=none, forget plot]		table [x=id, y=min]		{\openmpprefixseqn} \closedcycle;
	%\addplot [stack plots=y, fill=olive!40!green!60, fill opacity=0.4, draw opacity=0, area legend]	table [x=id, y expr=\thisrow{med}-\thisrow{min}]	{\openmpprefixseqn} \closedcycle;
	\addplot [fill=none, draw=blue, thick]		table [x=id, y=min]	{\openmpprefixseqn};
	\addlegendentry{{Seq. minimum}}
	\addplot [draw=blue, loosely dotted, thick]	table [x=id, y=med]	{\openmpprefixseqn};
	\addlegendentry{{Seq. median}}
	\addplot [fill=none, draw=red, thick]		table [x=id, y=min]	{\openmpprefixauxarrn};
	\addlegendentry{{Aux. Arr. minimum}}
	\addplot [draw=red, loosely dotted, thick]	table [x=id, y=med]	{\openmpprefixauxarrn};
	\addlegendentry{{Aux. Arr. median}}
	\addplot [fill=none, draw=green, thick]		table [x=id, y=min]	{\openmpprefixinplacen};
	\addlegendentry{{Inplace minimum}}
	\addplot [draw=green, loosely dotted, thick]table [x=id, y=med]	{\openmpprefixinplacen};
	\addlegendentry{{Inplace median}}
	\addplot [fill=none, draw=orange, thick]		table [x=id, y=min]	{\openmpprefixhillisn};
	\addlegendentry{{Hillis minimum}}
	\addplot [draw=orange, loosely dotted, thick]table [x=id, y=med]	{\openmpprefixhillisn};
	\addlegendentry{{Hillis median}}
	%\resetstackedplots

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per instance size} of the different algorithms in \textbf{OpenMP}. Raw data can be found in the appendix: \autoref{res-tbl:1-1-seq-n} \autoref{res-tbl:1-1-auxarr-n} \autoref{res-tbl:1-1-inplace-n} \autoref{res-tbl:1-1-hillis-n}}
\label{plot:1-1-n}
\end{figure}


\section{Cilk Prefix Sums}

For the Cilk project we had to come up with a task-parallel algorithm on our own and implement one of the ones previously used with OpenMP by using the data parallel construct from the lecture.
We chose to base both on the inplace algorithm but for the latter we did not use the abstracted data parallel construct but interwove it with the algorithm directly.

The task-parallel algorithm we used a typical recursive divide and conquer approach which allows for quite some parallelism but which was very hard to do right for all $n$.
We failed to come up with a proper solution and decided to solve this problem by rounding up to the next power of 2 before actually calling our algorithm.
The data-parallel algorithm does work with all $n$ but it was also quite tricky to accomplish this and the vast number of debug printfs are the (not so?) silent witnesses.

The Cilk framework in the form used by the lecture was abandoned after Intel bought the copyrights.
This missing maintenance and drawbacks in usability (C89 only, lots of bugs) are very annoying additionally to the unorthodox and hardly to grasp task-parallel concept (at least for us).

\pgfplotstableread[format=file,col sep=comma]{../../../data/2-cilk/p1/task-n.processed}\cilktaskn
\pgfplotstableread[format=file,col sep=comma]{../../../data/2-cilk/p1/data-n.processed}\cilkdatan
\pgfplotstableread[format=file,col sep=comma]{../../../data/2-cilk/p1/task-speedup.processed}\cilkspeedup

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	]
	\addplot [fill=none, draw=blue, thick]		table [x=id, y=min]	{\cilktaskn};
	\addlegendentry{{Task-p. minimum}}
	\addplot [draw=blue, loosely dotted, thick]	table [x=id, y=med]	{\cilktaskn};
	\addlegendentry{{Task-p. median}}
	\addplot [fill=none, draw=red, thick]		table [x=id, y=min]	{\cilkdatan};
	\addlegendentry{{Data-p. minimum}}
	\addplot [draw=red, loosely dotted, thick]	table [x=id, y=med]	{\cilkdatan};
	\addlegendentry{{Data-p. median}}
	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per instance size} of the \textbf{Data-parallel} and \textbf{Task-parallel algorithms} in \textbf{Cilk}. Raw data can be found in the appendix: \autoref{res-tbl:2-data-n} \autoref{res-tbl:2-task-n}}
\label{plot:2-n}
\end{figure}

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Threads},
	ylabel={Time [s]},
	%xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	reverse legend,
	ymin=0,
	]
	\addplot [stack plots=y, fill=none, draw=none, forget plot]		table [x=id, y=min]		{\cilkspeedup} \closedcycle;
	\addplot [stack plots=y, fill=green, fill opacity=0.4, draw opacity=0, area legend]	table [x=id, y expr=\thisrow{med}-\thisrow{min}]	{\cilkspeedup} \closedcycle;
	\addplot [stack plots=false, draw=black, thick]					table [x=id, y=med]		{\cilkspeedup};
	\addplot [stack plots=y, fill=red!50, fill opacity=0.4, draw opacity=0, area legend]table [x=id, y expr=\thisrow{max}-\thisrow{med}]	{\cilkspeedup} \closedcycle;

	\addlegendentry{{below med.}}
	\addlegendentry{{med.}}
	\addlegendentry{{above med.}}

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per number of threads} of the \textbf{Task-parallel algorithms} in \textbf{Cilk}. Raw data can be found in the appendix: \autoref{res-tbl:2-speedup}}
\label{plot:2-speedup}
\end{figure}


\section{MPI Prefix Sums}

For this assignment we had to compare three different algorithms: the simple sequential one and two versions of the algorithm laid out in the assignment.
The algorithm in the slides assumes the array to be already distributed to all hosts.
We actually prepare the full array in all processes and use only the block dedicated to that host respectively.
The benchmarking starts by taking a timestamp and the blocks are solved in parallel by all hosts first until they have to communicate.
Here the two algorithms differentiate into one version that just calls \texttt{MPI\_Exscan} and one that implements this manually.
This was straight forward to implement after figuring out how to map the operations on the array to data transfers between the hosts.
After that both algorithms trivialy fix their local block by adding the prefix sum of the previous block and benchmarking stops.

The results are quite interesting:
They show the huge overhead of MPI communication in general and especially between the nodes over Infiniband when comparing the timing of the sequential algorithm with the MPI-enabled ones when running on multiple nodes.
Also they suggest that our custom implementation of \texttt{MPI\_Exscan} is very competitive at least for large inputs.

\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/custom-speedup-100000.processed}\mpiprefixonehundredkcustom
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/native-speedup-100000.processed}\mpiprefixonehundredknative
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/seq-speedup-100000.processed}\mpiprefixonehundredkseq

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	xmin=0,
	]

	\addplot [fill=none, draw=blue, thick,			domain=1:560]		{0.000553};
	\addlegendentry{{Seq. minimum}}
	\addplot [draw=blue, loosely dotted, thick,		domain=1:560]		{0.000554};
	\addlegendentry{{Seq. median}}
	\addplot [fill=none, draw=red, thick]			table [x=id, y=min]	{\mpiprefixonehundredkcustom};
	\addlegendentry{{Custom minimum}}
	\addplot [draw=red, loosely dotted, thick]		table [x=id, y=med]	{\mpiprefixonehundredkcustom};
	\addlegendentry{{Custom median}}
	\addplot [fill=none, draw=green, thick]			table [x=id, y=min]	{\mpiprefixonehundredknative};
	\addlegendentry{{Native minimum}}
	\addplot [draw=green, loosely dotted, thick]	table [x=id, y=med]	{\mpiprefixonehundredknative};
	\addlegendentry{{Native median}}

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per number of threads} of the different algorithms in \textbf{MPI} for $n=100000$. Raw data can be found in the appendix: \autoref{res-tbl:3-2-custom-100k} \autoref{res-tbl:3-2-native-100k} \autoref{res-tbl:3-2-seq-100k}}
\label{plot:3-2-n}
\end{figure}


\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/custom-speedup-2_pow_24.processed}\mpiprefixpowtwentyfourcustom
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/native-speedup-2_pow_24.processed}\mpiprefixpowtwentyfournative
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/seq-speedup-2_pow_24.processed}\mpiprefixpowtwentyfourseq

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	xmin=0,
	]

	\addplot [fill=none, draw=blue, thick,			domain=1:560]		{0.058419};
	\addlegendentry{{Seq. minimum}}
	\addplot [draw=blue, loosely dotted, thick,		domain=1:560]		{0.059347};
	\addlegendentry{{Seq. median}}
	\addplot [fill=none, draw=red, thick]			table [x=id, y=min]	{\mpiprefixpowtwentyfourcustom};
	\addlegendentry{{Custom minimum}}
	\addplot [draw=red, loosely dotted, thick]		table [x=id, y=med]	{\mpiprefixpowtwentyfourcustom};
	\addlegendentry{{Custom median}}
	\addplot [fill=none, draw=green, thick]			table [x=id, y=min]	{\mpiprefixpowtwentyfournative};
	\addlegendentry{{Native minimum}}
	\addplot [draw=green, loosely dotted, thick]	table [x=id, y=med]	{\mpiprefixpowtwentyfournative};
	\addlegendentry{{Native median}}

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per number of threads} of the different algorithms in \textbf{MPI} for $n=2^{24}$. Raw data can be found in the appendix: \autoref{res-tbl:3-2-custom-pow24} \autoref{res-tbl:3-2-native-pow24} \autoref{res-tbl:3-2-seq-pow24}}
\label{plot:3-2-n}
\end{figure}


\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/custom-speedup-2_pow_26.processed}\mpiprefixpowtwentysixcustom
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/native-speedup-2_pow_26.processed}\mpiprefixpowtwentysixnative
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/seq-speedup-2_pow_26.processed}\mpiprefixpowtwentysixseq

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	xmin=0,
	]

	\addplot [fill=none, draw=blue, thick,			domain=1:560]		{0.246854};
	\addlegendentry{{Seq. minimum}}
	\addplot [draw=blue, loosely dotted, thick,		domain=1:560]		{0.2548015};
	\addlegendentry{{Seq. median}}
	\addplot [fill=none, draw=red, thick]			table [x=id, y=min]	{\mpiprefixpowtwentysixcustom};
	\addlegendentry{{Custom minimum}}
	\addplot [draw=red, loosely dotted, thick]		table [x=id, y=med]	{\mpiprefixpowtwentysixcustom};
	\addlegendentry{{Custom median}}
	\addplot [fill=none, draw=green, thick]			table [x=id, y=min]	{\mpiprefixpowtwentysixnative};
	\addlegendentry{{Native minimum}}
	\addplot [draw=green, loosely dotted, thick]	table [x=id, y=med]	{\mpiprefixpowtwentysixnative};
	\addlegendentry{{Native median}}

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per number of threads} of the different algorithms in \textbf{MPI} for $n=2^{26}$. Raw data can be found in the appendix: \autoref{res-tbl:3-2-custom-pow26} \autoref{res-tbl:3-2-native-pow26} \autoref{res-tbl:3-2-seq-pow26}}
\label{plot:3-2-n}
\end{figure}



\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/custom-speedup-2_pow_28.processed}\mpiprefixpowtwentyeightcustom
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/native-speedup-2_pow_28.processed}\mpiprefixpowtwentyeightnative
\pgfplotstableread[format=file,col sep=comma]{../../../data/3-mpi/p2/seq-speedup-2_pow_28.processed}\mpiprefixpowtwentyeightseq

\begin{figure}[h!]
\centering
\begin{tikzpicture}
\begin{axis}[
	width=0.8\linewidth,
	xlabel={Instance Size [array elements]},
	ylabel={Time [s]},
	xmode=log, ymode=log,
	enlarge x limits=false,
	axis on top,
	legend style={
		draw=none,
		cells={anchor=west},
		legend pos=outer north east,
	},
	%reverse legend,
	ymin=0,
	xmin=0,
	]

	\addplot [fill=none, draw=blue, thick,			domain=1:560]		{0.845252};
	\addlegendentry{{Seq. minimum}}
	\addplot [draw=blue, loosely dotted, thick,		domain=1:560]		{0.950762};
	\addlegendentry{{Seq. median}}
	\addplot [fill=none, draw=red, thick]			table [x=id, y=min]	{\mpiprefixpowtwentyeightcustom};
	\addlegendentry{{Custom minimum}}
	\addplot [draw=red, loosely dotted, thick]		table [x=id, y=med]	{\mpiprefixpowtwentyeightcustom};
	\addlegendentry{{Custom median}}
	\addplot [fill=none, draw=green, thick]			table [x=id, y=min]	{\mpiprefixpowtwentyeightnative};
	\addlegendentry{{Native minimum}}
	\addplot [draw=green, loosely dotted, thick]	table [x=id, y=med]	{\mpiprefixpowtwentyeightnative};
	\addlegendentry{{Native median}}

	\end{axis}
\end{tikzpicture}
\caption{Benchmark results showing \textbf{run time per number of threads} of the different algorithms in \textbf{MPI} for $n=2^{28}$. Raw data can be found in the appendix: \autoref{res-tbl:3-2-custom-pow28} \autoref{res-tbl:3-2-native-pow28} \autoref{res-tbl:3-2-seq-pow28}}
\label{plot:3-2-n}
\end{figure}
